{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5631613d",
   "metadata": {},
   "source": [
    "## 1. Loading Dataset and Dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d114554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f7ec88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve\n",
    "from lime.lime_tabular import LimeTabularExplainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c55469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "file_path = 'PhiUSIIL_Phishing_URL_Dataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc76cc00",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c2d039",
   "metadata": {},
   "source": [
    "### 2.1 Drop irrelevant Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6749b16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary categorical columns are already encoded\n",
    "# Drop ['FILENAME', 'URL', 'DOMAIN', 'TLD', 'TITLE'] columns,\n",
    "# as they are not needed for the model training, and causes issues with the model\n",
    "\n",
    "df = df.select_dtypes(include=['number']).copy()\n",
    "\n",
    "# Remove duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e2576a",
   "metadata": {},
   "source": [
    "### 2.2 Train-test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dda6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "X = df.iloc[:, :-1]  # All rows, all columns except the last one\n",
    "y = df.iloc[:, -1]   # All rows, only the last column\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "print(\"\\nSample of X_train:\\n\")\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f55372c",
   "metadata": {},
   "source": [
    "### 2.3 Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14170226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit only on training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(f\"Shape after scaling: X_train: {X_train_scaled.shape}, X_test: {X_test_scaled.shape}\")\n",
    "\n",
    "print(\"\\nSample of X_train_scaled:\\n\")\n",
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b8cf18",
   "metadata": {},
   "source": [
    "### 2.4 Compare SMOTE, ADASYN, BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1866feba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8f636af",
   "metadata": {},
   "source": [
    "### 2.5 Apply SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c58636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e9556c0",
   "metadata": {},
   "source": [
    "## 3. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60475f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize SelectKBest\n",
    "k = 20  # Change the number of features you want to select\n",
    "selector = SelectKBest(score_func=f_classif, k=k)\n",
    "\n",
    "# Fit on resampled training data\n",
    "X_train_selected = selector.fit_transform(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Apply the same selection on test data\n",
    "X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "# Get indices and scores of selected features\n",
    "selected_indices = selector.get_support(indices=True)\n",
    "scores = selector.scores_\n",
    "\n",
    "# Get the original feature names\n",
    "feature_names = X_train_scaled.columns\n",
    "selected_feature_names = [feature_names[i] for i in selected_indices]\n",
    "\n",
    "# Print selected features\n",
    "print(f\"Top {k} selected features:\\n\")\n",
    "print(selected_feature_names)\n",
    "\n",
    "print(\"\\nShape of selected training set:\", X_train_selected.shape)\n",
    "print(\"Shape of selected testing set:\", X_test_selected.shape)\n",
    "\n",
    "# Plot scores\n",
    "# --------------------------------------------------\n",
    "# Create figure 1920x1080 pixels at 100 DPI\n",
    "plt.figure(figsize=(19.2, 10.8))\n",
    "\n",
    "# Plot F-scores\n",
    "plt.barh(selected_feature_names, [scores[i] for i in selected_indices], color='skyblue', edgecolor='black')\n",
    "\n",
    "# Axis labels and title\n",
    "plt.xlabel(\"F-score\", fontsize=16)\n",
    "plt.title(f\"Top {k} Features via SelectKBest (ANOVA F-test)\", fontsize=20)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# Add gridlines for better readability\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust tick label sizes\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00c82bc",
   "metadata": {},
   "source": [
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e83ecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models dictionary to save best models\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e50091",
   "metadata": {},
   "source": [
    "### 4.1 Decision Tree Classifier with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aefe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier with GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "dt_params = {\n",
    "    'max_depth': [ 10],\n",
    "    'criterion': ['gini']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "dt = GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    dt_params,\n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "dt.fit(X_train_selected, y_train_resampled)\n",
    "\n",
    "# Save best model\n",
    "models['Decision Tree'] = dt.best_estimator_\n",
    "\n",
    "print(\"‚úÖ Decision Tree training complete and model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfec88c",
   "metadata": {},
   "source": [
    "### 4.2 Random Forest Classifier with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903a3d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_params = {'n_estimators': [100], 'max_depth': [20]}\n",
    "\n",
    "# GridSearchCV\n",
    "rf = GridSearchCV(RandomForestClassifier(random_state=42), rf_params, cv=3, scoring='f1', n_jobs=-1)\n",
    "\n",
    "# Fit model\n",
    "rf.fit(X_train_selected, y_train_resampled)\n",
    "\n",
    "# Save best model\n",
    "models['Random Forest'] = rf.best_estimator_\n",
    "\n",
    "print(\"‚úÖ Random Forest training complete and model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6aa0b6c",
   "metadata": {},
   "source": [
    "### 4.3 Logistic Regression with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051d8a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr_params = {'C': [1]}\n",
    "\n",
    "# GridSearchCV with L2 penalty\n",
    "lr = GridSearchCV(\n",
    "    LogisticRegression(penalty='l2', max_iter=1000, random_state=42),\n",
    "    lr_params,\n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "lr.fit(X_train_selected, y_train_resampled)\n",
    "\n",
    "# Save the best estimator\n",
    "models['Logistic Regression'] = lr.best_estimator_\n",
    "\n",
    "print(\"‚úÖ Logistic Regression training complete and model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678b9af9",
   "metadata": {},
   "source": [
    "### 4.4 KNN with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc020d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define KNN parameter grid\n",
    "knn_params = {\n",
    "    'n_neighbors': [5],\n",
    "    'weights': ['distance']\n",
    "}\n",
    "\n",
    "# Setup GridSearchCV\n",
    "knn = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    knn_params,\n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "knn.fit(X_train_selected, y_train_resampled)\n",
    "\n",
    "# Save best model\n",
    "models['KNN'] = knn.best_estimator_\n",
    "\n",
    "print(\"‚úÖ K-Nearest Neighbors training complete and model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4476f1b",
   "metadata": {},
   "source": [
    "### 4.5 Gradient Boosting Classifier with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b656240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid\n",
    "gbc_params = {\n",
    "    'n_estimators': [100],\n",
    "    'learning_rate': [0.1],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "gbc = GridSearchCV(\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    gbc_params,\n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "gbc.fit(X_train_selected, y_train_resampled)\n",
    "\n",
    "# Save best model\n",
    "models['Gradient Boosting'] = gbc.best_estimator_\n",
    "\n",
    "print(\"‚úÖ Gradient Boosting training complete and model saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02758c6",
   "metadata": {},
   "source": [
    "### 4.6 Support Vector Machine (SVM) with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbd37b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid\n",
    "svm_params = {\n",
    "    'C': [1],\n",
    "    'kernel': ['rbf'],\n",
    "    'gamma': ['scale']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "svm = GridSearchCV(\n",
    "    SVC(probability=True, random_state=42),\n",
    "    svm_params,\n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "svm.fit(X_train_selected, y_train_resampled)\n",
    "\n",
    "# Save best model\n",
    "models['SVM'] = svm.best_estimator_\n",
    "\n",
    "print(\"‚úÖ Support Vector Machine training complete and model saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d14a5a",
   "metadata": {},
   "source": [
    "### 4.7 XGBoost with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b1193b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Define parameter grid\n",
    "xgb_params = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [5],\n",
    "    'learning_rate': [0.1],\n",
    "    'subsample': [0.8, 1]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "xgb = GridSearchCV(\n",
    "    estimator=XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "    param_grid=xgb_params,\n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "xgb.fit(X_train_selected, y_train_resampled)\n",
    "\n",
    "# Save best model\n",
    "models['XGBoost'] = xgb.best_estimator_\n",
    "\n",
    "print(\"‚úÖ XGBoost training complete and model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc8fb6c",
   "metadata": {},
   "source": [
    "### 4.8 Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc86a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base learners (we can use simpler or diverse models)\n",
    "base_learners = [\n",
    "    ('decision_tree', models['Decision Tree']),\n",
    "    ('knn', models['KNN']),\n",
    "    ('svm', models['SVM'])\n",
    "]\n",
    "\n",
    "# Define meta-learner\n",
    "meta_learner = LogisticRegression(random_state=42, max_iter=5000)\n",
    "\n",
    "# Initialize Stacking Classifier\n",
    "stacking = StackingClassifier(\n",
    "    estimators=base_learners,\n",
    "    final_estimator=meta_learner,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    passthrough=True\n",
    ")\n",
    "\n",
    "# Fit stacking model\n",
    "stacking.fit(X_train_selected, y_train_resampled)\n",
    "\n",
    "# Save stacking model\n",
    "models['Stacking'] = stacking\n",
    "\n",
    "print(\"‚úÖ Stacking Classifier training complete and model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebe658c",
   "metadata": {},
   "source": [
    "## 5. Model Results and Performance Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c33252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüîç Model: {name}\")\n",
    "\n",
    "    # Predictions\n",
    "    y_train_pred = model.predict(X_train_selected)\n",
    "    y_test_pred = model.predict(X_test_selected)\n",
    "\n",
    "    # Probabilities (for AUC)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_test_proba = model.predict_proba(X_test_selected)[:, 1]\n",
    "    else:\n",
    "        # For models like SVM without predict_proba\n",
    "        y_test_proba = model.decision_function(X_test_selected)\n",
    "\n",
    "    # Accuracy\n",
    "    print(f\"‚úÖ Training Accuracy: {accuracy_score(y_train_resampled, y_train_pred):.4f}\")\n",
    "    print(f\"‚úÖ Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"\\nüìã Classification Report:\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "    # AUC-ROC\n",
    "    roc_auc = roc_auc_score(y_test, y_test_proba)\n",
    "    print(f\"üìà AUC-ROC Score: {roc_auc:.4f}\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    plt.figure(figsize=(8, 6), dpi=200)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f\"Confusion Matrix: {name}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\" \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc73f20d",
   "metadata": {},
   "source": [
    "## 6. LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09a7f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Make sure X_train_selected and X_test_selected are DataFrames\n",
    "X_train_selected = pd.DataFrame(X_train_selected)\n",
    "X_test_selected = pd.DataFrame(X_test_selected)\n",
    "\n",
    "# Assign feature names manually if needed\n",
    "X_train_selected.columns = [f\"feature_{i}\" for i in range(X_train_selected.shape[1])]\n",
    "X_test_selected.columns = X_train_selected.columns\n",
    "\n",
    "# 1. Initialize LIME Explainer\n",
    "explainer = LimeTabularExplainer(\n",
    "    training_data=X_train_selected.values,\n",
    "    feature_names=X_train_selected.columns.tolist(),\n",
    "    class_names=['Non-Phishing', 'Phishing'],\n",
    "    mode='classification'\n",
    ")\n",
    "\n",
    "# 2. Pick a random test sample\n",
    "sample_idx = np.random.randint(0, X_test_selected.shape[0])\n",
    "sample = X_test_selected.iloc[sample_idx]\n",
    "true_label = y_test.iloc[sample_idx]\n",
    "\n",
    "print(f\"üîé Sample index: {sample_idx}  |  True Label: {true_label}\")\n",
    "\n",
    "# Optional: collect all explanations into a single table\n",
    "all_explanations = []\n",
    "\n",
    "# 3. LIME Explain for each model\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nüîµ Explaining model: {model_name}\")\n",
    "\n",
    "    exp = explainer.explain_instance(\n",
    "        data_row=sample.values,\n",
    "        predict_fn=model.predict_proba\n",
    "    )\n",
    "\n",
    "    # Plot with 1080p resolution\n",
    "    fig = exp.as_pyplot_figure()\n",
    "    fig.set_size_inches(19.2, 10.8)\n",
    "    plt.title(f\"LIME Explanation for {model_name}\", fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # üîΩ Create explanation table\n",
    "    explanation_list = exp.as_list()\n",
    "    explanation_df = pd.DataFrame(explanation_list, columns=[\"Feature\", \"Weight\"])\n",
    "    explanation_df[\"Model\"] = model_name\n",
    "    explanation_df[\"Sample Index\"] = sample_idx\n",
    "    explanation_df[\"True Label\"] = true_label\n",
    "\n",
    "    # Display the explanation table\n",
    "    display(HTML(f\"<h3>LIME Explanation Table for <em>{model_name}</em></h3>\"))\n",
    "    display(explanation_df)\n",
    "\n",
    "    # Store for combined view\n",
    "    all_explanations.append(explanation_df)\n",
    "\n",
    "# üìä Optional: Combine all explanations\n",
    "combined_explanations_df = pd.concat(all_explanations, ignore_index=True)\n",
    "\n",
    "# Display combined table\n",
    "display(HTML(\"<h2>Combined LIME Explanation Table</h2>\"))\n",
    "display(combined_explanations_df)\n",
    "\n",
    "# Optional: Export to CSV\n",
    "# combined_explanations_df.to_csv(\"lime_explanations.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
